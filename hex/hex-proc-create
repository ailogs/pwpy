#! /bin/tcsh -f
#
# Create a new analysis directory for processing hex-style observations.
# The only work done here is to "shadow" the data into the analysis
# directory and flag out data outside of the observations' time range
# (in case the dataset is appended to multiple times during a loop
# observations). The next step is to flag and calibrate the data with 
# hex-proc-prep.

# Uncomment to debug the commands executed by this script
#set echo = 1

# Make sure the shell environment is set up
source `dirname $0`/hex-lib-checkenv

if ($#argv < 2) then
    echo "Usage: [summary file] [analysis dir]"
    echo "E.g.:  hex-3c48-hp7-summ-23:59:59a.hexsumm 3c48-1430"
    exit 1
endif

set workdir = ${argv[$#argv]}
mkdir -p $workdir


# Try to avoid overwriting existing datasets

if (-e $workdir/data-rawdata.txt) then
    echo "Error: Analysis directory $workdir seems to have already been created."
    echo "       (Remove $workdir/data-rawdata.txt to override this check.)"
    exit 1
endif


# Figure out whether we've been passed a summary file or (easter egg!)
# a list of UV datasets

if (-f $1 && $#argv == 2) then
    # Summary file.
    set summdir = `dirname "$1"`
    set tstart = `grep tstart "$1" |cut -d' ' -f2`
    set tend = `grep tend "$1" |cut -d' ' -f2`
    set nfull = `grep nfull "$1" |cut -d' ' -f2`

    grep success "$1" >& /dev/null
    if ($status) then
	echo "Warning: no success indicator in summary file."
	echo "  This observation may have failed or been aborted."
    endif

    # make sure to get them in proper order
    set relvises = (`grep scan "$1" |sort |cut -d' ' -f3`)
    set nvis = $#relvises

    if ($nfull != $nvis) then
	echo "Warning: this hex run didn't include all of the scans that "
	echo "  it should have. There may not be enough data to analyze."
    endif

    # Convert to absolute paths
    set vises = ()

    foreach rvis ($relvises)
	set vises = ($vises $summdir/$rvis)
    end
else
    set tstart = none
    set tend = none

    # List of UV datasets.
    @ nvis = $#argv - 1
    set vises = (${argv[1-$nvis]})

    # Check that that's actually what they are
    foreach vis ($vises)
	if (! -e $vis/visdata) then
	    echo "Error: arguments appear to include list of UV datasets, but"
	    echo "  no such file $vis/visdata"
	    exit 1
	endif
    end
endif


# Shadow the raw datasets into the work directory
#
# FIXME: this is where we should do sanity-checking on the input data:
# that they are all of the same field at the same frequency, we're only
# dealing with one timechunk of data (if indeed that restriction is to be
# imposed on hex obs analysis), etc.

set old = `pwd`
@ n = 0

foreach vis ($vises)
    set vis = `cd $vis ; pwd`
    set vdup = vis`printf %02d $n`

    if (-d $workdir/$vdup) then
	echo "Error: shadowed dataset $workdir/$vdup already exists."
	exit 1
    endif

    echo "Shadow $vis -> $workdir/$vdup"
    echo $vis >>$workdir/data-rawdata.txt
    mkdir $workdir/$vdup
    cd $workdir/$vdup

    foreach fb (`cd $vis && ls -1`)
	set fn = $vis/$fb

	if ($fb == visdata) then
	    ln -s $fn visdata
	else
	    cp -a $fn .
	endif
    end

    @ n = $n + 1
    cd $old
end


# Record the relevant time range if specified

echo tstart "$tstart" >$workdir/data-databounds.txt
echo tend "$tend" >>$workdir/data-databounds.txt

exit 0
