An ATA-42/FX64 Flagging and Calibration Cookbook
Peter Williams <pwilliams@astro.berkeley.edu>
============================================================



Here's a quick cookbook that gives my standard ATA data flagging and
calibration procedures. I'm not an experienced radio astronomer, and
no one is truly experienced at doing science with ATA data, so all of
these instructions should be regarded as provisional. I'll happily
accept suggestions and corrections.

One implication of this document being a "cookbook" is that I've
skipped some justifications and explanations in favor of concision. If
the effect of a step is unclear, you should probably read the
documentation for its associated task; if its rationale is unclear,
you should probably ask Peter.

The master copy of this document is stored in the "mmm" Subversion
repository on svn.hcro.org. I've put it here since, at the moment,
writing this document as simple text file is the most appealing
thing. Perhaps this should be exported to log.hcro.org eventually.




TERMINOLOGY
============================================================

Right now, observations with the ATA generate data in the form of
Miriad datasets named

       fx64a-SRC-FREQ_HALF

Where SRC is the name of the source you're observing (as recognized by
the ATA catalog system), FREQ is your observing frequency in MHz, and
HALF is (what I call) the "correlator half" of the spectrum you're
observing and is either "1" or "2". The correlator outputs 1024
channels: the first 512 are in "half 1" and the other 512 are in 
"half 2".

This cookbook is written as if your observations have one calibrator
and one science target taken at one frequency. Extrapolation to more
complicated observations is your job. In the example commands, the
observed source is referred to either as CAL, or TARG, or SRC. If CAL
is used, the command is run on a calibrator dataset; if TARG is used,
it's run on a science target dataset; and if SRC is used, it's run on
both kinds of dataset.

An "antpol" is a particular antenna-polarization combination. The FX64
correlator has 64 antpol inputs. When all 42 ATA antennas are fully
functional, there are 84 antpols being fed into the processing room.

In this document, an indented line starting with "$" indicates a
command that could be run in a shell. Command arguments enclosed in
square brackets ("[]") are optional. Lines starting with "<" indicate
sample output of the preceding command.

When processing a dataset in some way that generates a new Miriad
dataset, my convention is to name the new dataset as the old one,
followed by a period (".") and a few letters indicating what kind of
processing happened. For instance, if FX-calibrating a dataset, I
usually name the new dataset with a ".fxx" or ".fxy" at the end, the
final letter indicating which polarization was used. (The FX
calibration done by UVCAL can't handle more than on parallel-hand
polarization at once.) E.g.,

  $ uvcal options=fxcal select='pol(xx)' vis=fx64a-SRC-FREQ_HALF \
    out=fx64a-SRC-FREQ_HALF.fxx

or

  $ uvaver interval=10 vis=fx64a-SRC-FREQ_HALF out=fx64a-SRC-FREQ_HALF.av




PYTHON SCRIPTS
============================================================

Many of these steps depend on Python scripts, though effort has been
made to not require them when possible and to describe what is going
on underneath the hood in case the scripts aren't available.

The scripts live in the pwilliams/fancy directory of the MMM
Subversion repository. Because Python is an interpreted language, the
scripts themselves are portable across CPU architectures, but the
bridge between them and Miriad is not. The easiest way to be able to
run the is to use Peter's prebuilt bridge libraries. You can use this
setup on your machine by sourcing some setup scripts that Peter has
prepared.  If you use a Bourne shell (sh, bash), run

  $ source /cosmic1/pkwill/usemir.sh

If you use a C shell (csh, tcsh), run

  $ source /cosmic1/pkwill/usemir.csh

(Note the different extension.) If the bridge libraries haven't been
built for your particular OS and CPU, the setup script will let you
know about this fact and exit; in that case, you will unfortunately
not be able to run the Python scripts.

Documentation for the scripts should be available by running

  $ mirhelp scriptname.py

in the usual manner. If this results in a list of no files 
"matching 'scriptname.py'", try running

  $ mirpyhelp.py scriptname.py

Some of the Python scripts require only the Miriad-Python bridge and
do not overlap in functionality with existing Miriad tasks; others are
more sophisticated and fit in more tightly with PKGW's particular
workflow. Brief notes on these latter scripts are given inside
sections delimited

  [[Python note: ... ]]

These notes assume some level of familiarity with PKGW's suite of
Python scripts and can be ignored if you so desire.




DATA PREPARATION RECIPE
============================================================

There are a few preliminary steps that I run before working with the
data in any serious way. These are a few massaging steps that are
essentially automatable.

* Glue together all half-1 and half-2 datasets. This gives you fewer
  files to deal with and means that more data will be going into your
  antenna gains solutions. Unfortunately, some Miriad tasks choke on
  1024-channel datasets; they will have to be run with a "line="
  keyword limiting the number of channels used.

  At the moment, the files generated by the correlator can have
  different start times in the two halves, which make the standard
  Miriad task UVGLUE inappropriate for this task. The Python script
  ATAGLUE.PY glues the two halves together correctly.

  $ ataglue.py vis=fx64a-SRC-FREQ_1,fx64a-SRC-FREQ_2 \
    out=fx64a-SRC-FREQ

  For data generated before May 1, 2008, a bad C board caused portions
  of some spectra to be corrupted and have very high amplitudes. When
  gluing together two spectra, these data can cause the rest of their
  spectra to be badly damaged by quantization in the Miriad data
  format. This can be prevented by giving ATAGLUE.PY the argument
  "options=badc1", which flags channels 512 - 768 of antpols 1X, 16X,
  19X, 23X, and 37X. Due to rewirings of the correlator, these may not
  be the right antpols to flag. You should look at your data to check
  where the bad C data are before using this option. (If your bad C
  data are in a different place, a new option called "badc2" will have
  to be created.) The easiest way to determine the affected antpols is to
  plot the data and find them visually.

  $ smauvspec device=1/xs axis=ch,bo select='pol(xx,yy),-auto' nxy=NX,NY \
    vis=fx64a-SRC-FREQ_2

* On all datasets, attempt to correct for amplitude loss due to the
  relatively long FX64 integration time and the fact that we do not
  currently have fringe rotation in our correlator.

  $ fringefix.py maxscale=2 vis=fx64a-SRC-FREQ out=fx64a-SRC-FREQ.ff
  
  PKGW is a little uncertain of the correctness of this step and
  of whether it should be applied to both cal and target
  datasets. Hopefully we will soon get fringe rotation and it won't
  matter anymore.

  Unfortunately, the amplitude loss seen in ATA-43/FX64 data does not
  quite match theoretical explanations, so the corrections applied by
  this script introduce infidelities of their own. But hopefully,
  those infidelities are less severe than those in the uncorrected
  data.

* On all datasets, run an FX calibration (that is, divide
  cross-correlations by auto-correlations). We hope that this smoothes
  out the bandpass somewhat, and it also makes quantification of
  the antenna gains easier.

  $ uvcal options=fxcal,unflagged select='pol(xx)' \
    vis=fx64a-SRC-FREQ.ff out=SRC-FREQ-xx
  $ uvcal options=fxcal,unflagged select='pol(yy)' \
    vis=fx64a-SRC-FREQ.ff out=SRC-FREQ-yy

  Different polarizations need to be processed separately due to the
  way the FX cal procedure is implemented. Splitting the data here is
  somewhat helpful down the road as SELFCAL has the same limitation.

  If you're doing spectral line work and a line of interest shows up
  in the autocorrelations, the above command will mess up your line
  data. PKGW does not know what to do about this, but it wouldn't be
  the worst thing to just skip this step and hope SMAMFCAL (below)
  comes up with good bandpass solutions.

  The "unflagged" option makes UVCAL not write out visibilities that
  have been completely flagged, making your output files somewhat
  smaller.

You should now have a bunch of prepped datasets called SRC-FREQ-POL,
where POL is one of "xx" or "yy". You may want to back these data up
if you want to revert some of your flagging and calibration
operations.




FLAGGING RECIPE
============================================================

PKGW's steps for flagging observations are:

* The DC channel of the correlator is always bad. This is channel 513
  in Miriad's 1-based channel-numbering scheme:

  $ uvflag flagval=f line=chan,513,1 vis=SRC-FREQ-POL

  for all SRC, FREQ and POL.

* The edges of the ATA bandpass are always very low-amplitude and are
  likely to suffer from quantization errors. The usual practice is to
  flag the 100 channels on each edge of the bandpass.

  $ uvflag flagval=f line=chan,100,1 vis=SRC-FREQ-POL
  $ uvflag flagval=f line=chan,100,925 vis=SRC-FREQ-POL

[[Python note: The multiflag command to encapsulating the above two
steps is:

  > chan=100,1;1,513;100,925

If the file containing that line was called generic.mf, you'd run

  $ multiflag2 spec=generic.mf freq=FREQ vis=VIS1,VIS2,VIS3,...

where FREQ is the observation frequency in MHz of the specified UV
datasets.]]

* Experience shows that there is a fair level of crosstalk between
  antpols that are on the same ADC card that also have the same Walsh
  function applied to them. The data from baselines corresponding to these
  antpols have unusable data.

[[Python note: A script called walsh-flags.py will generate
appropriate multiflag commands based on the conflicts. Run it as

  $ walsh-flags.py SRC-FREQ-POL >walsh.mf

where SRC-FREQ-POL is an arbitrary dataset. The flagging commands can
then be applied with multiflag2.]]

  David MacMahon has a quick shell script that looks at the "history"
  item of an ATA dataset and reports what baselines are have the same
  Walsh function and are digitized on the same ADC card. These
  baselines should be flagged. The script is available on the HCRO
  computers and is called walsh_adc_conflict.sh:

  $ walsh_adc_conflict.sh SRC-FREQ-POL
  <   fx64a   54   i14.fxa in2   4jyb   35Y   Walsh 0  
  <   fx64a   55   i14.fxa in3   5cyb   39Y   Walsh 0  
  <
  <   fx64a   18   i05.fxa in2   1kyb   10Y   Walsh 2  
  <   fx64a   19   i05.fxa in3   2hyb   18Y   Walsh 2  
  < 
  <   fx64a   56   i15.fxa in0   1byb    2Y   Walsh 2  
  <   fx64a   57   i15.fxa in1   4kyb   36Y   Walsh 2 
  $ uvflag flagval=f select='ant(ANT1)(ANT2),pol(POL)' vis=SRC-FREQ-POL
  $ uvflag ...

  With ANT1, ANT2, and POL above corresponding to the pairs listed in
  the output of walsh_adc_conflict.sh. (If you are working with
  datasets that have been separated by polarization, you need to run
  this once with each parallel-hand pol.) In the sample output above,
  you'd flag

  ant(35)(39),pol(yy)
  ant(10)(18),pol(yy)
  ant(2)(23),pol(yy)

  The bad baselines identified by walsh_adc_conflict.sh are a function
  of the physical configuration of the correlator, and so will not
  vary across a single observing run. So you can run
  walsh_adc_conflict.sh on one dataset from your observation, figure
  out the appropriate UVFLAG commands, and then apply them to all of
  your datasets.

* As mentioned earlier, observations made before May 1, 2008 will
  contain some data that went through a bad C board. The effect of the
  bad card was to ruin a quarter of the band for some antpols. If
  these data weren't flagged in the prep stage, they should be flagged
  now. Check if the gluing process has resulting in the corruption of
  entire visibility records or just the directly-affected portion of
  the band.

  The section of the band involving the affected antpol should be
  flagged out on all baselines.

  $ uvflag flagval=f line=chan,128,START select='ant(ANT),pol(POL)' \
    vis=SRC-FREQ-POL

  for all SRC, FREQ, and affected POL.
  
* If your data were taken during the daytime, you may have to flag out
  baselines showing solar interference. I do not know of a good easy
  way to identify these baselines. Baselines with short UV distances
  are likely candidates, since the solar radiation will be more
  correlated on small distances. Baselines with solar interference
  tend to have amplitudes that oscillate across the band. You can look
  for these manually by looking at spectra:

  $ smauvspec device=1/xs axis=ch,bo select='pol(xx),-auto' nxy=NX,NY \
    vis=SRC-FREQ-POL [interval=MINUTES]

  The dataset used can probably be arbitrary. PKGW assumes that
  baselines that show interference in one dataset will show
  interference in all datasets. This assumption may not be correct.

  Set NX and NY to something that will keep spectra small but legible
  in your PGPLOT window. Adding an "interval" keyword to time-average
  your data may wash out the amplitude oscillations. Presumably, solar
  interference that shows up in the XX pol should also show up in YY,
  but this presumption hasn't been examined.

* At this point in the recipe, the egregiously bad baselines should
  have been flagged out. Now, some attempts at automated RFI flagging
  can be made.

  One way to do this is to average together *all* visibilities over
  everything but channel, so that those channels with consistently
  high amplitudes (due to high-duty-cycle RFI) can be identified.

[[Python note: PGKW's interactive implementation of this approach
lives in a module called amprfi.py and can be started on the
command-line with "amprfi". There is not currently any documentation
of this tool. The script below is much lower-level and performs only
the averaging step -- it is up to you to choose what to do with the
averaged data.]]

  PKGW has a noninteractive script that does this computation called
  AMPADD.PY. It writes out the average spectrum to a logfile that can
  then be plotted. One can then pick out the RFI-afflicted channels by
  eye.

  $ ampadd.py vis='*-FREQ-POL' log=rfi-FREQ-POL.txt

  One way to visualize the results is with Gnuplot:

  $ echo "plot 'rfi-FREQ-POL.txt' using 1:3 with lines" \
    |gnuplot -persist -

  The logfile contains three columns: channel number, channel
  frequency (GHz), and averaged amplitude (arbitrary units). It should
  be easy to use your favorite analysis tool to work with the data it
  contains.

  There are several other scripts that attempt to flag RFI
  automatically in various ways. One of Karto's is described at

  http://log.hcro.org/node/571

* Now that RFI is flagged out, the passband-averaged visibility
  amplitudes and phases should be somewhat believable.

  One useful technique is to plot baseline phase as a function of time
  at this point:

  $ uvplt device=/xs select=-auto axis=ti,ph vis=CAL-FREQ-POL

  Bad baselines or antennas will have phases that vary essentially
  randomly, while good ones will be more consistent.

* Closure-based flagging is also possible after RFI flagging.

  If you have observations of a point-source-like calibrator, closure
  phases can be examined to identify bad antennas and
  baselines. Unfortunately, with 42 antennas, there are *very* many
  closure triples to examine. The Python script CLOSANAL.PY
  computes closure triples and lists the triples, baselines, and
  antennas that have the worst closure properties. 

  $ closanal.py vis=CAL-FREQ-POL interval=10

  You should time-average over at least a few minutes to damp out the
  effects of noise. You can get CLOSANAL.PY to print out the *best*
  triples, baselines, and antennas by giving it the keyword
  "options=best".

* FIXME: Phase stddev-based flagging

* FIXME: paying attention to what ataalarms -l has complained about.

* FIXME: iterative flagging based on self-cal results.




CALIBRATION RECIPE
============================================================

PKGW's generic steps for calibrating observations are:

* Run a bandpass and amplitude calibration on your calibrator
  datasets:

  $ smamfcal options=opolyfit select=-auto polyfit=7 \
    refant=REFANT line=chan,824,101 vis=CAL-FREQ-POL

  for both POL. If you're doing spectral line work, you will want to
  temporarily flag out the line so that SMAMFCAL doesn't calibrate it
  away. PGKW has no experience doing this, though.

  The invocation above will smooth out the fit bandpass points, which
  should be helpful. The derived bandpass solutions can be seen with

  $ gpplt device=1/xs options=bandpass vis=CAL-FREQ-POL

  The "line" keyword in the above SMAMFCAL commands may be needed
  because, in at least some cases, SMAMFCAL crashes if it tries to
  process all 1024 channels. Whether this is a problem for you will
  probably depend on the particular build of Miriad that you're
  using. (It may affect at least 64-bit Linux builds.) The crash isn't
  a major issue because 200 edge channels are all flagged anyway, and
  SMAMFCAL can successfully process the unflagged 824 center channels.

* If Miriad isn't familiar with your source, SMAMFCAL won't set the
  antenna amplitudes to anything useful. (If it does know your source,
  you will see a message such as "Using known frequency variation of
  3c286.") If your calibrator is a nice bright point source, remedy
  this with a SELFCAL:

  $ selfcal select=-auto options=amp,noscale flux=FLUX vis=CAL-FREQ-POL

  for both POL. (Assuming an unpolarized source and so on.) The
  "select=-auto" line is essential; otherwise SELFCAL will produce
  bogus results. It is also essential to have only one polarization
  present in the UV dataset being self-cal'ed.

  FIXME: more advanced usage with a self-cal model and such.

* Miriad stores a header in its dataset indicating how far in time the
  calibration routines will be willing to extrapolate antenna
  gains. The default used by SMAMFCAL is half a day, whereas the
  default that SELFCAL may overwrite is 5 minutes. The first number is
  too large but probably not a problem in practice; the second number
  is often too small, and can result in data in your target dataset
  being discarded when applying gain solutions from the
  calibrator. You can tweak the setting with:

  $ puthd type=double value=INTERVALDAYS in=CAL-FREQ-POL/interval

  for both POL, where INTERVALDAYS is the extrapolation interval in
  days. I suggest 0.02, about half an hour, as a reasonable value. (In
  the above command, the final "/interval" should be included as shown
  -- this tells PUTHD which keyword to set.)

* Now copy antenna gains from the calibration datasets to the target
  datasets:

  $ gpcopy vis=CAL-FREQ-POL out=TARG-FREQ-POL

  for all FREQ and POL.

  Now all of your datasets should have reasonable antenna and bandpass
  calibrations applied. Hooray!

* WARNING: Are the steps described below actually a good idea? I am
  not sure.

  Extra credit: If you're imaging your target and want to try to clean
  things up, it may help to phase self-calibrate your target
  datasets. To do this, you need a model of your target image, most
  likely created by the CLEAN task. We'll assume this dataset is
  called "TARG-FREQ.cl". So, the first step is to image the target
  without any further processing and create that dataset.

  Even though we only want to self-calibrate in phase, doing so
  overwrites antenna amplitude solutions, so the previous calibrated
  dataset needs to be UVCAT'ed to rewrite the data with the amplitude
  solutions applied:

  $ uvcat vis=TARG-FREQ-POL out=TARG-FREQ-POL.phsc

  for both POL. Then, a phase-only selfcal can be reapplied:

  $ selfcal options=ph,mfs model=TARG-FREQ.cl vis=TARG-FREQ-POL.phsc

  Hopefully, an image generated after running this step will be
  cleaner than the previous one. Iterate until happy.

* FIXME: polarization calibration. No one has dared to do this yet, as
  far as I know.
